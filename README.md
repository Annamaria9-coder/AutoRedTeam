# AutoRedTeam

AutoRedTeam is an automated security testing tool for AI applications. It helps identify vulnerabilities in Large Language Models (LLMs) by running a series of tests to detect jailbreaks, data leakage, hallucinations, and harmful content generation.

## Features

- Connect to any LLM API endpoint
- Run customizable security tests
- Get detailed reports on vulnerabilities
- Beautiful glassmorphism UI design
- Risk scoring and categorization

## How to Use

1. Enter your API endpoint and key
2. Select which test categories to run
3. Click "Run Security Tests"
4. Review the detailed results and risk assessment

## Demo

Visit the [live demo](https://YOUR_USERNAME.github.io/AutoRedTeam/)

## License

MIT
